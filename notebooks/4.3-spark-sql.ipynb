{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ec2d0d-3d4b-4101-adf4-5ceb9b5834e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Проверяем доступность spark\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4737c6-e693-4d86-b73b-93c7e9ad6a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем наличие нужных параметров в конфигурации\n",
    "print(spark.conf.get(\"spark.sql.extensions\"))\n",
    "print(spark.conf.get(\"spark.sql.catalog.spark_catalog\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e631743-f9a9-49eb-a731-61238e1bd198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем базу данных\n",
    "spark.sql(\"create database module_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c029e1-5511-45cf-8257-1f6cad8a1617",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T08:05:19.945193Z",
     "iopub.status.busy": "2024-07-25T08:05:19.943619Z",
     "iopub.status.idle": "2024-07-25T08:05:34.525083Z",
     "shell.execute_reply": "2024-07-25T08:05:34.523887Z",
     "shell.execute_reply.started": "2024-07-25T08:05:19.945120Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/07/25 08:05:22 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/07/25 08:05:34 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider delta. Persisting data source table `module_4`.`lesson_43` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создание таблицы при помощи DDL\n",
    "table_ddl = \"\"\"CREATE OR REPLACE TABLE module_4.lesson_43 (\n",
    "  id INT,\n",
    "  run_parameters STRING,\n",
    "  status STRING,\n",
    "  status_message STRING\n",
    ")\n",
    "USING DELTA;\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(table_ddl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70bbe8b9-fb20-480a-8162-7c6d8fb0f8df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T11:44:59.897469Z",
     "iopub.status.busy": "2024-07-25T11:44:59.895996Z",
     "iopub.status.idle": "2024-07-25T11:45:12.892599Z",
     "shell.execute_reply": "2024-07-25T11:45:12.891613Z",
     "shell.execute_reply.started": "2024-07-25T11:44:59.897396Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+\n",
      "|            col_name|           data_type|comment|\n",
      "+--------------------+--------------------+-------+\n",
      "|                  id|                 int|       |\n",
      "|      run_parameters|              string|       |\n",
      "|              status|              string|       |\n",
      "|      status_message|              string|       |\n",
      "|                    |                    |       |\n",
      "|      # Partitioning|                    |       |\n",
      "|     Not partitioned|                    |       |\n",
      "|                    |                    |       |\n",
      "|# Detailed Table ...|                    |       |\n",
      "|                Name|  module_4.lesson_43|       |\n",
      "|            Location|s3a://yc-dataproc...|       |\n",
      "|            Provider|               delta|       |\n",
      "|               Owner|             jupyter|       |\n",
      "|    Table Properties|[delta.minReaderV...|       |\n",
      "+--------------------+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Форматированная инфомрация о таблице\n",
    "spark.sql(\"describe formatted module_4.lesson_43\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48ab658a-4563-42cc-8a5e-698b9a85565a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T08:05:42.987657Z",
     "iopub.status.busy": "2024-07-25T08:05:42.986452Z",
     "iopub.status.idle": "2024-07-25T08:05:43.567666Z",
     "shell.execute_reply": "2024-07-25T08:05:43.566443Z",
     "shell.execute_reply.started": "2024-07-25T08:05:42.987603Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+------------------+-----------+--------------------+--------------------+-------------------+----------------+--------+-----------+----------+----------------+----------------+--------------------+\n",
      "|format|                  id|              name|description|            location|           createdAt|       lastModified|partitionColumns|numFiles|sizeInBytes|properties|minReaderVersion|minWriterVersion|       tableFeatures|\n",
      "+------+--------------------+------------------+-----------+--------------------+--------------------+-------------------+----------------+--------+-----------+----------+----------------+----------------+--------------------+\n",
      "| delta|50d416ea-20cd-4f0...|module_4.lesson_43|       null|s3a://yc-dataproc...|2024-07-25 08:05:...|2024-07-25 08:05:21|              []|       0|          0|        {}|               1|               2|[appendOnly, inva...|\n",
      "+------+--------------------+------------------+-----------+--------------------+--------------------+-------------------+----------------+--------+-----------+----------+----------------+----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Детальное описание Delta таблицы\n",
    "spark.sql(\"describe detail module_4.lesson_43\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70c1041d-6549-4e25-bbc3-d5dd54372677",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T08:05:46.353679Z",
     "iopub.status.busy": "2024-07-25T08:05:46.352497Z",
     "iopub.status.idle": "2024-07-25T08:05:48.032276Z",
     "shell.execute_reply": "2024-07-25T08:05:48.030786Z",
     "shell.execute_reply.started": "2024-07-25T08:05:46.353626Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------+--------+--------------------+--------------------+----+--------+---------+-----------+--------------+-------------+----------------+------------+--------------------+\n",
      "|version|          timestamp|userId|userName|           operation| operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics|userMetadata|          engineInfo|\n",
      "+-------+-------------------+------+--------+--------------------+--------------------+----+--------+---------+-----------+--------------+-------------+----------------+------------+--------------------+\n",
      "|      0|2024-07-25 08:05:21|  null|    null|CREATE OR REPLACE...|{isManaged -> tru...|null|    null|     null|       null|  Serializable|         true|              {}|        null|Apache-Spark/3.3....|\n",
      "+-------+-------------------+------+--------+--------------------+--------------------+----+--------+---------+-----------+--------------+-------------+----------------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# История изменений Delta таблицы\n",
    "spark.sql(\"describe history module_4.lesson_43\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fdf87e6-4ae0-4922-8a98-7827fead72ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T08:05:59.490880Z",
     "iopub.status.busy": "2024-07-25T08:05:59.489910Z",
     "iopub.status.idle": "2024-07-25T08:06:06.526620Z",
     "shell.execute_reply": "2024-07-25T08:06:06.525737Z",
     "shell.execute_reply.started": "2024-07-25T08:05:59.490838Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Записываем в таблицу 1 строку\n",
    "spark.sql(\"insert into module_4.lesson_43 values (1, 'some params', 'Run', '')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6698a972-444a-4074-90bf-8431e1a9fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ошибка при insert\n",
    "spark.sql(\"insert into module_4.lesson_43 values (100, null, 'Error')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "225bfbc5-7585-4f28-8b58-cc0079f97810",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T08:06:42.185357Z",
     "iopub.status.busy": "2024-07-25T08:06:42.184074Z",
     "iopub.status.idle": "2024-07-25T08:06:46.743975Z",
     "shell.execute_reply": "2024-07-25T08:06:46.743006Z",
     "shell.execute_reply.started": "2024-07-25T08:06:42.185307Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Запись строки с указанием колонок\n",
    "spark.sql(\"insert into module_4.lesson_43 (id, run_parameters, status, status_message) values (2, 'another params', 'Success', 'Data inserted successfully')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78867b7e-fe70-4c07-b222-bb40027166ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T08:07:06.076052Z",
     "iopub.status.busy": "2024-07-25T08:07:06.075146Z",
     "iopub.status.idle": "2024-07-25T08:07:08.762759Z",
     "shell.execute_reply": "2024-07-25T08:07:08.761714Z",
     "shell.execute_reply.started": "2024-07-25T08:07:06.076008Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+-------+--------------------+\n",
      "| id|run_parameters| status|      status_message|\n",
      "+---+--------------+-------+--------------------+\n",
      "|  2|another params|Success|Data inserted suc...|\n",
      "|  1|   some params|    Run|                    |\n",
      "+---+--------------+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Проверка результата\n",
    "spark.table(\"module_4.lesson_43\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd87d4c8-136d-4069-8edf-70c296729073",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T08:08:24.299311Z",
     "iopub.status.busy": "2024-07-25T08:08:24.297953Z",
     "iopub.status.idle": "2024-07-25T08:08:31.285420Z",
     "shell.execute_reply": "2024-07-25T08:08:31.284419Z",
     "shell.execute_reply.started": "2024-07-25T08:08:24.299264Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[num_affected_rows: bigint]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обновление строки с id = 1\n",
    "spark.sql(\"update module_4.lesson_43 set status='Warning' where id = 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a67422f5-1bb9-4a95-bace-d84b3a80a64c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T08:08:33.886019Z",
     "iopub.status.busy": "2024-07-25T08:08:33.885172Z",
     "iopub.status.idle": "2024-07-25T08:08:35.398359Z",
     "shell.execute_reply": "2024-07-25T08:08:35.397417Z",
     "shell.execute_reply.started": "2024-07-25T08:08:33.885970Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+-------+--------------------+\n",
      "| id|run_parameters| status|      status_message|\n",
      "+---+--------------+-------+--------------------+\n",
      "|  2|another params|Success|Data inserted suc...|\n",
      "|  1|   some params|Warning|                    |\n",
      "+---+--------------+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Проверка результата\n",
    "spark.table(\"module_4.lesson_43\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "105d0ef8-b197-4d9c-b054-2e371bd16d86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T08:09:44.544189Z",
     "iopub.status.busy": "2024-07-25T08:09:44.542853Z",
     "iopub.status.idle": "2024-07-25T08:09:49.197424Z",
     "shell.execute_reply": "2024-07-25T08:09:49.196399Z",
     "shell.execute_reply.started": "2024-07-25T08:09:44.544145Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Перезаписываем данные в таблице\n",
    "spark.sql(\"insert overwrite table module_4.lesson_43 (id, run_parameters, status, status_message) values (3, 'correct params', 'Success', 'Correct data inserted successfully')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "770b141e-72a3-42fd-b5c7-b14257f7eefb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T08:09:53.872408Z",
     "iopub.status.busy": "2024-07-25T08:09:53.871124Z",
     "iopub.status.idle": "2024-07-25T08:09:55.137676Z",
     "shell.execute_reply": "2024-07-25T08:09:55.136836Z",
     "shell.execute_reply.started": "2024-07-25T08:09:53.872360Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+-------+----------------------------------+\n",
      "|id |run_parameters|status |status_message                    |\n",
      "+---+--------------+-------+----------------------------------+\n",
      "|3  |correct params|Success|Correct data inserted successfully|\n",
      "+---+--------------+-------+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Проверяем успешность перезаписи\n",
    "spark.table(\"module_4.lesson_43\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41ce54c3-c23d-4208-a90d-3591189685f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T08:14:20.930820Z",
     "iopub.status.busy": "2024-07-25T08:14:20.929566Z",
     "iopub.status.idle": "2024-07-25T08:14:21.018834Z",
     "shell.execute_reply": "2024-07-25T08:14:21.017884Z",
     "shell.execute_reply.started": "2024-07-25T08:14:20.930766Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создаем временную таблицу\n",
    "spark.sql(\"\"\"CREATE OR REPLACE TEMP VIEW lesson_43_updates AS SELECT * FROM VALUES\n",
    "  (4, 'wrong params', 'Failed', 'Error: OutOfMemoryException'),\n",
    "  (1, 'upload test table', 'Success', 'Table was uploaded'),\n",
    "  (3, 'correct settings', 'Success', 'Empty message'),\n",
    "  (5, 'correct settings', 'Failed', 'Unavailable source cluster')\n",
    "  AS tab(id, run_parameters, status, status_message);\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f75b37b5-ae57-4b7c-8d4e-b830202cb525",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T08:15:37.490634Z",
     "iopub.status.busy": "2024-07-25T08:15:37.489600Z",
     "iopub.status.idle": "2024-07-25T08:15:45.086015Z",
     "shell.execute_reply": "2024-07-25T08:15:45.084540Z",
     "shell.execute_reply.started": "2024-07-25T08:15:37.490590Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/07/25 08:15:39 WARN HintErrorLogger: Hint (strategy=broadcast) is not supported in the query: build left for full outer join.\n",
      "24/07/25 08:15:40 WARN HintErrorLogger: Hint (strategy=broadcast) is not supported in the query: build left for full outer join.\n",
      "24/07/25 08:15:40 WARN HintErrorLogger: Hint (strategy=broadcast) is not supported in the query: build left for full outer join.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[num_affected_rows: bigint, num_updated_rows: bigint, num_deleted_rows: bigint, num_inserted_rows: bigint]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Операция объединения\n",
    "spark.sql(\"\"\"MERGE INTO module_4.lesson_43\n",
    "    USING lesson_43_updates\n",
    "    ON module_4.lesson_43.id = lesson_43_updates.id\n",
    "    WHEN MATCHED THEN UPDATE SET *\n",
    "    WHEN NOT MATCHED THEN INSERT *;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b70933c-f566-4f26-b55a-efd224b82faa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T08:16:00.187965Z",
     "iopub.status.busy": "2024-07-25T08:16:00.186448Z",
     "iopub.status.idle": "2024-07-25T08:16:01.504236Z",
     "shell.execute_reply": "2024-07-25T08:16:01.503332Z",
     "shell.execute_reply.started": "2024-07-25T08:16:00.187918Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+-------+---------------------------+\n",
      "|id |run_parameters   |status |status_message             |\n",
      "+---+-----------------+-------+---------------------------+\n",
      "|1  |upload test table|Success|Table was uploaded         |\n",
      "|3  |correct settings |Success|Empty message              |\n",
      "|4  |wrong params     |Failed |Error: OutOfMemoryException|\n",
      "|5  |correct settings |Failed |Unavailable source cluster |\n",
      "+---+-----------------+-------+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Проверяем успешность вставки\n",
    "spark.table(\"module_4.lesson_43\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38c64503-4d62-41b7-85a6-39bc357cc690",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T08:20:36.949928Z",
     "iopub.status.busy": "2024-07-25T08:20:36.948653Z",
     "iopub.status.idle": "2024-07-25T08:20:37.529487Z",
     "shell.execute_reply": "2024-07-25T08:20:37.528496Z",
     "shell.execute_reply.started": "2024-07-25T08:20:36.949879Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------+--------+--------------------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "|version|          timestamp|userId|userName|           operation| operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n",
      "+-------+-------------------+------+--------+--------------------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "|      5|2024-07-25 08:15:41|  null|    null|               MERGE|{predicate -> (sp...|null|    null|     null|          4|  Serializable|        false|{numTargetRowsCop...|        null|Apache-Spark/3.3....|\n",
      "|      4|2024-07-25 08:09:45|  null|    null|               WRITE|{mode -> Overwrit...|null|    null|     null|          3|  Serializable|        false|{numFiles -> 1, n...|        null|Apache-Spark/3.3....|\n",
      "|      3|2024-07-25 08:08:27|  null|    null|              UPDATE|{predicate -> (id...|null|    null|     null|          2|  Serializable|        false|{numRemovedFiles ...|        null|Apache-Spark/3.3....|\n",
      "|      2|2024-07-25 08:06:42|  null|    null|               WRITE|{mode -> Append, ...|null|    null|     null|          1|  Serializable|         true|{numFiles -> 1, n...|        null|Apache-Spark/3.3....|\n",
      "|      1|2024-07-25 08:06:01|  null|    null|               WRITE|{mode -> Append, ...|null|    null|     null|          0|  Serializable|         true|{numFiles -> 1, n...|        null|Apache-Spark/3.3....|\n",
      "|      0|2024-07-25 08:05:21|  null|    null|CREATE OR REPLACE...|{isManaged -> tru...|null|    null|     null|       null|  Serializable|         true|                  {}|        null|Apache-Spark/3.3....|\n",
      "+-------+-------------------+------+--------+--------------------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Просмотриваем историю операций\n",
    "spark.sql(\"describe history module_4.lesson_43\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2b0167b-7433-43d4-a126-6d342efb6aef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T08:21:09.946423Z",
     "iopub.status.busy": "2024-07-25T08:21:09.945309Z",
     "iopub.status.idle": "2024-07-25T08:21:14.006998Z",
     "shell.execute_reply": "2024-07-25T08:21:14.005922Z",
     "shell.execute_reply.started": "2024-07-25T08:21:09.946374Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+-------+--------------------+\n",
      "| id|run_parameters| status|      status_message|\n",
      "+---+--------------+-------+--------------------+\n",
      "|  2|another params|Success|Data inserted suc...|\n",
      "|  1|   some params|    Run|                    |\n",
      "+---+--------------+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Вывод данных по указанной версии\n",
    "spark.sql(\"select * from module_4.lesson_43 version as of 2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1dce2226-0012-43ba-a7f4-064a3b866c18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T08:22:44.149740Z",
     "iopub.status.busy": "2024-07-25T08:22:44.148678Z",
     "iopub.status.idle": "2024-07-25T08:22:48.283126Z",
     "shell.execute_reply": "2024-07-25T08:22:48.282177Z",
     "shell.execute_reply.started": "2024-07-25T08:22:44.149693Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+-------+----------------------------------+\n",
      "|id |run_parameters|status |status_message                    |\n",
      "+---+--------------+-------+----------------------------------+\n",
      "|3  |correct params|Success|Correct data inserted successfully|\n",
      "+---+--------------+-------+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Вывод данных по указанной временной метке\n",
    "spark.sql(f\"select * from module_4.lesson_43 timestamp as of '2024-07-25 08:09:46'\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
