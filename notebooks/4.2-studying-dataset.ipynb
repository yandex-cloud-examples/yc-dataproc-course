{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60fafe3-d288-4c92-ad88-be249298c10d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T17:25:30.167778Z",
     "iopub.status.busy": "2024-04-22T17:25:30.166996Z",
     "iopub.status.idle": "2024-04-22T17:26:19.671017Z",
     "shell.execute_reply": "2024-04-22T17:26:19.670386Z",
     "shell.execute_reply.started": "2024-04-22T17:25:30.167738Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for an Apache Livy session to start...\n",
      "Apache Livy session has started.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv('s3a://yc-dataproc-tasks/data/transaction_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2b846e-578f-4105-8e10-ee77cc299105",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   ===============    Обзор полученных данных   ==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32795d5d-82e2-4ea7-bddb-7fcae0aa02c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T17:32:42.224036Z",
     "iopub.status.busy": "2024-04-22T17:32:42.223429Z",
     "iopub.status.idle": "2024-04-22T17:32:43.264710Z",
     "shell.execute_reply": "2024-04-22T17:32:43.264119Z",
     "shell.execute_reply.started": "2024-04-22T17:32:42.224006Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+--------------------+--------+--------------------+----------------------+-----------+--------------+\n",
      "|UserId|TransactionId|     TransactionTime|ItemCode|     ItemDescription|NumberOfItemsPurchased|CostPerItem|       Country|\n",
      "+------+-------------+--------------------+--------+--------------------+----------------------+-----------+--------------+\n",
      "|278166|      6355745|Sat Feb 02 12:50:...|  465549|FAMILY ALBUM WHIT...|                     6|      11.73|United Kingdom|\n",
      "|337701|      6283376|Wed Dec 26 09:06:...|  482370|LONDON BUS COFFEE...|                     3|       3.52|United Kingdom|\n",
      "|267099|      6385599|Fri Feb 15 09:45:...|  490728|SET 12 COLOUR PEN...|                    72|        0.9|        France|\n",
      "|380478|      6044973|Fri Jun 22 07:14:...|  459186|UNION JACK FLAG L...|                     3|       1.73|United Kingdom|\n",
      "|    -1|      6143225|Mon Sep 10 11:58:...| 1733592| WASHROOM METAL SIGN|                     3|        3.4|United Kingdom|\n",
      "|285957|      6307136|Fri Jan 11 09:50:...| 1787247|CUT GLASS T-LIGHT...|                    12|       3.52|United Kingdom|\n",
      "|345954|      6162981|Fri Sep 28 10:51:...|  471576|NATURAL SLATE CHA...|                     9|       6.84|United Kingdom|\n",
      "|    -1|      6143225|Mon Sep 10 11:58:...|  447867| SKULLS WRITING SET |                   120|       1.15|United Kingdom|\n",
      "|339822|      6255403|Mon Dec 10 09:23:...| 1783845|MULTI COLOUR SILV...|                    36|       1.18|United Kingdom|\n",
      "|328440|      6387425|Sat Feb 16 10:35:...|  494802|SET OF 6 RIBBONS ...|                    36|       3.99|United Kingdom|\n",
      "+------+-------------+--------------------+--------+--------------------+----------------------+-----------+--------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Показываем 10 строк в обрезанном состоянии\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79c6fd1f-2643-479f-a1da-f5c8f4b380a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T17:33:34.950391Z",
     "iopub.status.busy": "2024-04-22T17:33:34.949672Z",
     "iopub.status.idle": "2024-04-22T17:33:36.001622Z",
     "shell.execute_reply": "2024-04-22T17:33:36.000940Z",
     "shell.execute_reply.started": "2024-04-22T17:33:34.950339Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+----------------------------+--------+---------------------------------+----------------------+-----------+--------------+\n",
      "|UserId|TransactionId|TransactionTime             |ItemCode|ItemDescription                  |NumberOfItemsPurchased|CostPerItem|Country       |\n",
      "+------+-------------+----------------------------+--------+---------------------------------+----------------------+-----------+--------------+\n",
      "|278166|6355745      |Sat Feb 02 12:50:00 IST 2019|465549  |FAMILY ALBUM WHITE PICTURE FRAME |6                     |11.73      |United Kingdom|\n",
      "|337701|6283376      |Wed Dec 26 09:06:00 IST 2018|482370  |LONDON BUS COFFEE MUG            |3                     |3.52       |United Kingdom|\n",
      "|267099|6385599      |Fri Feb 15 09:45:00 IST 2019|490728  |SET 12 COLOUR PENCILS DOLLY GIRL |72                    |0.9        |France        |\n",
      "|380478|6044973      |Fri Jun 22 07:14:00 IST 2018|459186  |UNION JACK FLAG LUGGAGE TAG      |3                     |1.73       |United Kingdom|\n",
      "|-1    |6143225      |Mon Sep 10 11:58:00 IST 2018|1733592 |WASHROOM METAL SIGN              |3                     |3.4        |United Kingdom|\n",
      "+------+-------------+----------------------------+--------+---------------------------------+----------------------+-----------+--------------+\n"
     ]
    }
   ],
   "source": [
    "# Выбирает из датафрейма n верхних строк\n",
    "df.limit(5).show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b46fcd7-7325-49d8-9e1d-b2b022847a4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T17:30:26.950323Z",
     "iopub.status.busy": "2024-04-22T17:30:26.949612Z",
     "iopub.status.idle": "2024-04-22T17:30:27.997633Z",
     "shell.execute_reply": "2024-04-22T17:30:27.996927Z",
     "shell.execute_reply.started": "2024-04-22T17:30:26.950284Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(UserId=278166, TransactionId=6355745, TransactionTime='Sat Feb 02 12:50:00 IST 2019', ItemCode=465549, ItemDescription='FAMILY ALBUM WHITE PICTURE FRAME', NumberOfItemsPurchased=6, CostPerItem=11.73, Country='United Kingdom'),\n",
      " Row(UserId=337701, TransactionId=6283376, TransactionTime='Wed Dec 26 09:06:00 IST 2018', ItemCode=482370, ItemDescription='LONDON BUS COFFEE MUG', NumberOfItemsPurchased=3, CostPerItem=3.52, Country='United Kingdom')]\n",
      "[Row(UserId=278166, TransactionId=6355745, TransactionTime='Sat Feb 02 12:50:00 IST 2019', ItemCode=465549, ItemDescription='FAMILY ALBUM WHITE PICTURE FRAME', NumberOfItemsPurchased=6, CostPerItem=11.73, Country='United Kingdom'), Row(UserId=337701, TransactionId=6283376, TransactionTime='Wed Dec 26 09:06:00 IST 2018', ItemCode=482370, ItemDescription='LONDON BUS COFFEE MUG', NumberOfItemsPurchased=3, CostPerItem=3.52, Country='United Kingdom')]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "# Получаем массив n строк\n",
    "pp = pprint.PrettyPrinter()\n",
    "pp.pprint(df.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3753197b-8020-49ce-a594-e3b5b3e8d811",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T17:37:39.726118Z",
     "iopub.status.busy": "2024-04-22T17:37:39.725416Z",
     "iopub.status.idle": "2024-04-22T17:37:40.776314Z",
     "shell.execute_reply": "2024-04-22T17:37:40.775710Z",
     "shell.execute_reply.started": "2024-04-22T17:37:39.726081Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(UserId=278166, TransactionId=6355745, TransactionTime='Sat Feb 02 12:50:00 IST 2019', ItemCode=465549, ItemDescription='FAMILY ALBUM WHITE PICTURE FRAME', NumberOfItemsPurchased=6, CostPerItem=11.73, Country='United Kingdom'),\n",
      " Row(UserId=337701, TransactionId=6283376, TransactionTime='Wed Dec 26 09:06:00 IST 2018', ItemCode=482370, ItemDescription='LONDON BUS COFFEE MUG', NumberOfItemsPurchased=3, CostPerItem=3.52, Country='United Kingdom'),\n",
      " Row(UserId=267099, TransactionId=6385599, TransactionTime='Fri Feb 15 09:45:00 IST 2019', ItemCode=490728, ItemDescription='SET 12 COLOUR PENCILS DOLLY GIRL ', NumberOfItemsPurchased=72, CostPerItem=0.9, Country='France')]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "# Показываем 3 строки в обрезанном состоянии\n",
    "pp = pprint.PrettyPrinter()\n",
    "pp.pprint(df.limit(3).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b568b069-ac0e-44e8-b475-9177476209c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   ===============    Изучение структуры данных   ==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a23c52b-969b-4463-9380-34e12c86aa83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T17:58:10.219510Z",
     "iopub.status.busy": "2024-04-22T17:58:10.218544Z",
     "iopub.status.idle": "2024-04-22T17:58:10.260818Z",
     "shell.execute_reply": "2024-04-22T17:58:10.260118Z",
     "shell.execute_reply.started": "2024-04-22T17:58:10.219469Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UserId',\n",
      " 'TransactionId',\n",
      " 'TransactionTime',\n",
      " 'ItemCode',\n",
      " 'ItemDescription',\n",
      " 'NumberOfItemsPurchased',\n",
      " 'CostPerItem',\n",
      " 'Country']\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "# Выбирает из датафрейма n верхних строк\n",
    "pp = pprint.PrettyPrinter()\n",
    "pp.pprint(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86b7d19c-6345-4818-b296-4c5867c22ec5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T18:36:32.904039Z",
     "iopub.status.busy": "2024-04-22T18:36:32.903348Z",
     "iopub.status.idle": "2024-04-22T18:36:32.953230Z",
     "shell.execute_reply": "2024-04-22T18:36:32.952602Z",
     "shell.execute_reply.started": "2024-04-22T18:36:32.904001Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выводим список атрибутов с помощью метода dtypes\n",
      "[('UserId', 'int'),\n",
      " ('TransactionId', 'int'),\n",
      " ('TransactionTime', 'string'),\n",
      " ('ItemCode', 'int'),\n",
      " ('ItemDescription', 'string'),\n",
      " ('NumberOfItemsPurchased', 'int'),\n",
      " ('CostPerItem', 'double'),\n",
      " ('Country', 'string')]\n",
      "\n",
      "Выводим список атрибутов с помощью метода schema\n",
      "StructType(List(StructField(UserId,IntegerType,true),StructField(TransactionId,IntegerType,true),StructField(TransactionTime,StringType,true),StructField(ItemCode,IntegerType,true),StructField(ItemDescription,StringType,true),StructField(NumberOfItemsPurchased,IntegerType,true),StructField(CostPerItem,DoubleType,true),StructField(Country,StringType,true)))\n",
      "\n",
      "Преобразовываем все атрибуты с типом IntegerType в DoubleType\n",
      "[StructField(UserId,DoubleType,true),\n",
      " StructField(TransactionId,DoubleType,true),\n",
      " StructField(TransactionTime,StringType,true),\n",
      " StructField(ItemCode,DoubleType,true),\n",
      " StructField(ItemDescription,StringType,true),\n",
      " StructField(NumberOfItemsPurchased,DoubleType,true),\n",
      " StructField(CostPerItem,DoubleType,true),\n",
      " StructField(Country,StringType,true)]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter()\n",
    "print(\"Выводим список атрибутов с помощью метода dtypes\")\n",
    "pp.pprint(df.dtypes)\n",
    "print(\"\\nВыводим список атрибутов с помощью метода schema\")\n",
    "pp.pprint(df.schema)\n",
    "\n",
    "df_fields = df.schema.fields\n",
    "\n",
    "print(\"\\nПреобразовываем все атрибуты с типом IntegerType в DoubleType\")\n",
    "new_schema = StructType([StructField(field.name, DoubleType(), field.nullable) if field.dataType == IntegerType() else field for field in df_fields])\n",
    "\n",
    "pp.pprint(new_schema.fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73068e48-97ee-4000-a151-a3bda43732d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9277066-af82-4ed9-8db4-4dfcb3d31833",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T18:41:41.139163Z",
     "iopub.status.busy": "2024-04-22T18:41:41.138297Z",
     "iopub.status.idle": "2024-04-22T18:41:46.211322Z",
     "shell.execute_reply": "2024-04-22T18:41:46.210631Z",
     "shell.execute_reply.started": "2024-04-22T18:41:41.139120Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- UserId: integer (nullable = true)\n",
      " |-- TransactionId: integer (nullable = true)\n",
      " |-- TransactionTime: string (nullable = true)\n",
      " |-- ItemCode: integer (nullable = true)\n",
      " |-- ItemDescription: string (nullable = true)\n",
      " |-- NumberOfItemsPurchased: integer (nullable = true)\n",
      " |-- CostPerItem: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "df = spark\\\n",
    "        .read\\\n",
    "        .option(\"inferSchema\", True)\\\n",
    "        .option(\"header\", True)\\\n",
    "        .csv('s3a://yc-dataproc-tasks/data/transaction_data.csv')\n",
    "\n",
    "# Выбирает из датафрейма n верхних строк\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05406c4-98f4-43e0-a783-46f78d04de54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,lit\n",
    "from datetime import datetime\n",
    "\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "df.withColumn('processed_dttm', lit(current_datetime)).show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803d5fd8-3a38-4a79-83a8-b0104c377884",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.select(\"UserId\", \"Country\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d854bc-c895-4f5a-82ff-55b3b2279e27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.select(\"Country\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083db375-2b09-4315-a913-acc017d2e9c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "\n",
    "schema = StructType([ \\\n",
    "      StructField(\"UserId\", IntegerType()), \\\n",
    "      StructField(\"TransactionId\", IntegerType()), \\\n",
    "      StructField(\"TransactionTime\", StringType()), \\\n",
    "      StructField(\"ItemCode\", IntegerType()), \\\n",
    "      StructField(\"ItemDescription\", StringType()), \\\n",
    "      StructField(\"NumberOfItemsPurchased\", StringType()), \\\n",
    "      StructField(\"CostPerItem\", StringType()), \\\n",
    "      StructField(\"Country\", StringType()) \\\n",
    "    ])\n",
    "        \n",
    "df = spark\\\n",
    "        .read\\\n",
    "        .option(\"header\", True)\\\n",
    "        .schema(schema)\\\n",
    "        .csv('s3a://yc-dataproc-tasks/data/transaction_data.csv')\n",
    "    \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c07a112-9566-4d8c-94c3-ce182a157a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   ===============    Манипуляция со столбцами   ==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8120dfe-5337-4660-8030-8ff2200dace5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit\n",
    "\n",
    "# Выбор столбцов\n",
    "print(\"Передаем на вход массив атрибутов\")\n",
    "df.select(df.columns).show(2, False)\n",
    "\n",
    "print(\"Атрибуты по именам\")\n",
    "df.select(\"UserId\", \"Country\").show(2, False)\n",
    "\n",
    "print(\"Используем объект Column\")\n",
    "df.select((col(\"UserId\") * 100).alias(\"UserId\"), col(\"Country\"), lit(\"hello World\").alias(\"greetings\")).show(2, False)\n",
    "\n",
    "print(\"Обращение к атрибуту\")\n",
    "df.select(df.ItemCode, (df.TransactionId - 1000000).alias(\"newTransaction\")).show(2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9cbac8-6ba5-4efd-ae0c-382f160e287c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "\n",
    "# Выбор столбцов\n",
    "df\\\n",
    "    .dropDuplicates([\"Country\"])\\\n",
    "    .selectExpr(\"UserId\",\\\n",
    "                \"date_format(to_timestamp(TransactionTime, 'E MMM dd HH:mm:ss z yyyy'), 'HH:mm:ss.SSS yyyy/MMM/dd') as timestamp\",\\\n",
    "                \"concat(Country, ' test') as cntr\",\\\n",
    "                \"'hello world!' as greeting\"\n",
    "               )\\\n",
    "    .show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada5a729-8071-414a-a64a-935abb3f07ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Добавление и изменение атрибутов\n",
    "from pyspark.sql.functions import when, lower, regexp_replace, length, expr\n",
    "\n",
    "df\\\n",
    "    .select(\"ItemCode\", \"Country\")\\\n",
    "    .dropDuplicates([\"Country\"])\\\n",
    "    .withColumn(\"spaceCount\", when(length(regexp_replace(col(\"Country\"), \"\\S\", \"\")) == 1, \"Single Space\")\n",
    "                .when(length(regexp_replace(col(\"Country\"), \"\\S\", \"\")) > 1, \"Multiple Space\")\n",
    "                .otherwise(\"No spaces\")\n",
    "               )\\\n",
    "    .withColumn(\"ItemCode\", expr(\"case when ItemCode > 450000 then ItemCode + 500000 else round(sqrt(ItemCode), 2) end\"))\\\n",
    "    .show(30, truncate = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d61e97-8b0a-4b98-acf2-01cbf8d23e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   ===============    Манипуляция со строками датафрейма   ==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8881dbc9-735e-468b-8a22-a2eef84f4bca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Сортировка\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_without_duplicates = df.select(\"UserId\", \"TransactionId\", \"ItemCode\").dropDuplicates([\"UserId\"])\n",
    "\n",
    "df_without_duplicates.sort(col(\"UserId\")).show(10)\n",
    "print(\"Сортировка с использованием sort\")\n",
    "df_without_duplicates.sort(col(\"UserId\").desc(), col(\"ItemCode\").asc()).show(10)\n",
    "print(\"Сортировка с использованием orderBy\")\n",
    "df_without_duplicates.orderBy(col(\"UserId\").desc(), col(\"ItemCode\").asc()).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290272bd-40d7-4a86-8e9a-2a3cee485e4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Фильтрация\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "item_df = df.select(\"ItemCode\", \"ItemDescription\", \"CostPerItem\")\n",
    "\n",
    "print(\"Фильтрация с использованием where\")\n",
    "item_df.where((col(\"CostPerItem\") > 2.0) & (col(\"CostPerItem\") < 3.0)).show(truncate = False)\n",
    "print(\"Фильтрация с использованием filter\")\n",
    "item_df.filter((col(\"CostPerItem\") > 2.0) & (col(\"ItemDescription\").like(\"LUNCH%\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5298ae1-0d67-48d6-8461-1540c0e9eefe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Получение уникальных строк\n",
    "user_df = df.select(\"UserId\", \"TransactionId\", \"Country\")\n",
    "\n",
    "print(\"Убираем полные дубли (по всем строкам)\")\n",
    "user_df.distinct().sort(\"UserId\", \"Country\").show(10)\n",
    "print(\"Убираем дубли только для атрибута UserId\")\n",
    "user_df.dropDuplicates([\"UserId\"]).sort(\"UserId\").show(10)\n",
    "print(\"Убираем дубли для атрибутов UserId и Country\")\n",
    "user_df.dropDuplicates([\"UserId\", \"Country\"]).sort(\"UserId\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2f0957-775c-4c3f-acd5-33229ee39d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   ===============    Агрегаты и обогащение   ==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15c9dc9-9568-47e0-a527-f14708539a3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, count, min, max, sum\n",
    "\n",
    "# Получаем среднюю стоимость для каждого товара и количество купленных товаров\n",
    "print(\"Получаем среднюю стоимость товара и сумму, сколько раз товар был куплен\")\n",
    "df.select(\"ItemCode\", \"CostPerItem\", \"NumberOfItemsPurchased\")\\\n",
    "    .groupBy(\"ItemCode\")\\\n",
    "    .agg(avg(\"CostPerItem\").alias(\"AverageCost\"), sum(\"NumberOfItemsPurchased\").alias(\"CountOfPurchasedItems\"))\\\n",
    "    .show(10, False)\n",
    "\n",
    "# Получаем количество товаров, которое приобрел каждый пользователь\n",
    "print(\"Получаем данные о том, сколько товаров приобрел каждый пользователь\")\n",
    "df.select(\"UserId\", \"ItemCode\").distinct().groupBy(\"UserId\").agg(count(\"*\").alias(\"ItemCount\")).show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7b3c42-5fec-4613-ae63-32aa92daef59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit\n",
    "from datetime import datetime\n",
    "\n",
    "# Определяем текущую временную метку\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Обогащаем датафрейм новым полем - информация о времени обработки датафрейма\n",
    "df.select(\"UserId\", \"TransactionId\", \"ItemCode\").withColumn('processed_dttm', lit(current_datetime)).show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3888e289-3258-4a6e-90cd-88ed26926dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   ===============    Функции   ==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf53168-71bc-4715-bd98-4cfc305a7b47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lower, upper, substring, split, trim, regexp_replace, length\n",
    "\n",
    "# Функции для работы со строками\n",
    "df\\\n",
    "    .dropDuplicates([\"Country\"])\\\n",
    "    .limit(10)\\\n",
    "    .select(\n",
    "        \"Country\",\\\n",
    "        lower(\"Country\").alias(\"lower\"),\\\n",
    "        upper(\"Country\").alias(\"upper\"),\\\n",
    "        substring(\"Country\", 1,3).alias(\"substring\"),\\\n",
    "        split(\"Country\", \" \").alias(\"split\"),\n",
    "        trim(\"Country\").alias(\"trim\"),\\\n",
    "        regexp_replace(\"Country\", \"e\", \"EE\").alias(\"regexpl_replace\"),\\\n",
    "        length(\"Country\").alias(\"length\")\\\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaeb04e-6d8c-4a5e-80b3-00249e322538",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import abs, round, ceil, pow, sqrt\n",
    "\n",
    "# Функции для работы с числами\n",
    "\n",
    "df\\\n",
    "    .dropDuplicates([\"CostPerItem\"])\\\n",
    "    .limit(15)\\\n",
    "    .select(\\\n",
    "        \"CostPerItem\",\\\n",
    "        abs(\"CostPerItem\").alias(\"abs\"),\\\n",
    "        ceil(\"CostPerItem\").alias(\"ceil\"),\\\n",
    "        round(pow(\"CostPerItem\", 2), 3).alias(\"powWithRound\"),\\\n",
    "        sqrt(abs(\"CostPerItem\")).alias(\"sqrt\")\\\n",
    "    ).sort(\"CostPerItem\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9fe901-2140-4622-b3d0-42e7e571808e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, current_date, current_timestamp, dayofmonth, date_add, date_format, to_timestamp, trunc, month, year\n",
    "\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "\n",
    "# Функции для работы с датой и временем\n",
    "df\\\n",
    "    .select(\\\n",
    "            col(\"TransactionTime\"),\\\n",
    "            current_date().alias(\"CurrentDate\"),\\\n",
    "            current_timestamp().alias(\"CurrentTimestamp\"),\\\n",
    "            trunc(current_timestamp(), \"month\").alias(\"Trunc\"),\\\n",
    "            to_timestamp(col(\"TransactionTime\"), \"E MMM dd HH:mm:ss z yyyy\").alias(\"TransformedTranscation\"),\\\n",
    "            date_format(date_add(current_timestamp(), 30), \"dd/MM/yyyy\").alias(\"DateAdd\")\\\n",
    "           )\\\n",
    "    .withColumn(\"year\", year(\"TransformedTranscation\"))\\\n",
    "    .withColumn(\"month\", month(\"TransformedTranscation\"))\\\n",
    "    .withColumn(\"day\", dayofmonth(\"TransformedTranscation\"))\\\n",
    "    .show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c91b53-50de-4f8b-a9d0-e8913882112b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array_contains, array_join, array_sort, col, size, split\n",
    "\n",
    "# Функции для работы с массивами\n",
    "df\\\n",
    "    .select(col(\"Country\"), split(col(\"Country\"), \" \").alias(\"splittedCountry\"))\\\n",
    "    .distinct()\\\n",
    "    .sort(col(\"Country\").desc())\\\n",
    "    .select(col(\"Country\"),\\\n",
    "            col(\"splittedCountry\"),\\\n",
    "            array_contains(col(\"splittedCountry\"), \"United\").alias(\"contains\"),\\\n",
    "            size(col(\"splittedCountry\")).alias(\"size\"),\\\n",
    "            array_join(array_sort(col(\"splittedCountry\")), \"_\").alias(\"join\")\\\n",
    "           )\\\n",
    "    .show(20, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
